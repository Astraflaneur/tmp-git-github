{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f0474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Sample input and target\n",
    "x = torch.randn(10, 5)  # 10 samples, 5 features\n",
    "y = torch.randint(0, 2, (10,))  # Binary labels (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c19950",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(5, 3)\n",
    "        self.fc2 = nn.Linear(3, 2)  # Output logits for 2 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab2b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1):  # One epoch for demo\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x)\n",
    "\n",
    "    # Basic resourcefulness: Print shapes\n",
    "    #print(\"Model output shape:\", out.shape)  # Expected: (10, 2)\n",
    "    #print(\"Target shape:\", y.shape)          # Expected: (10,)\n",
    "    \n",
    "    # Print actual values for first few samples\n",
    "    #print(\"Output (first 2):\", out[:2])\n",
    "    #print(\"Target (first 2):\", y[:2])\n",
    "    \n",
    "    try:\n",
    "        loss = criterion(out, y)\n",
    "    except RuntimeError as e:\n",
    "        print(\"❌ Runtime error during loss computation:\")\n",
    "        print(e)\n",
    "        import pdb; pdb.set_trace()  # Interactive debug\n",
    "    else:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"✅ Step completed. Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d964a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_output_shape():\n",
    "    test_x = torch.randn(4, 5)\n",
    "    test_model = SimpleNN()\n",
    "    out = test_model(test_x)\n",
    "    assert out.shape == (4, 2), \"Model output shape should be (batch_size, 2)\"\n",
    "\n",
    "test_model_output_shape()\n",
    "print(\"✅ Shape test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01e5269",
   "metadata": {},
   "source": [
    "<div align=\"center\">  \n",
    "  <img src=\"../asset/fail%20early%20fail%20fast%20fail%20often.webp\" >  \n",
    "  <br><br>\n",
    "</div>\n",
    "\n",
    "\n",
    "Fail-fast debugging is about **catching errors as close to their source as possible**, instead of letting them cascade into confusing tracebacks.\n",
    "\n",
    "#### How to Implement Fail Fast:\n",
    "\n",
    "* **Assert assumptions immediately:**\n",
    "\n",
    "  ```python\n",
    "  assert x.dim() == 2, \"Expected 2D tensor for input x\"\n",
    "  assert y.max() < num_classes, \"Target label exceeds number of classes\"\n",
    "  ```\n",
    "\n",
    "* **Check for `NaN`, `inf`, or exploding values early:**\n",
    "\n",
    "  ```python\n",
    "  if torch.isnan(x).any():\n",
    "      raise ValueError(\"Found NaN in input tensor x\")\n",
    "  if x.abs().max() > 1e6:\n",
    "      raise ValueError(\"Input values exploding: check your initialization\")\n",
    "  ```\n",
    "\n",
    "* **Validate function inputs:**\n",
    "\n",
    "  ```python\n",
    "  def train_step(x, y):\n",
    "      if not isinstance(x, torch.Tensor):\n",
    "          raise TypeError(\"Expected torch.Tensor for input x\")\n",
    "  ```\n",
    "\n",
    "* **Use dummy batches before full training:**\n",
    "\n",
    "  ```python\n",
    "  dummy_x = torch.randn(2, 5)\n",
    "  dummy_y = torch.randint(0, 3, (2,))\n",
    "  loss = F.cross_entropy(model(dummy_x), dummy_y)\n",
    "  print(f\"Dummy loss: {loss.item():.4f}\")\n",
    "  ```\n",
    "\n",
    "* **Write helper test cases**:\n",
    "  Create mini test functions to verify key behavior:\n",
    "\n",
    "  ```python\n",
    "  def test_shapes():\n",
    "      out = model(torch.randn(4, 5))\n",
    "      assert out.shape == (4, 3), f\"Unexpected output shape: {out.shape}\"\n",
    "  ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df58785",
   "metadata": {},
   "source": [
    "## How to look up things\n",
    "\n",
    "### Read the **Traceback** Carefully\n",
    "The last line shows the error type and location. Traceback lines show the call stack, top is where it **crashed**, bottom is where it **started**. Look for things like `Expected input shape (N, C, H, W) but got (N, D)` to understand shape mismatches.\n",
    "\n",
    "### Use **Google + Stackoverflow + ChatGPT** Effectively\n",
    "- Copy-paste error messages (or parts) into Google or StackOverflow. Add keywords like `\"PyTorch\"`, `\"CrossEntropyLoss\"` or `\"tensor shape\"` to narrow down. Use [Discuss PyTorch](https://discuss.pytorch.org) – great place for subtle issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
